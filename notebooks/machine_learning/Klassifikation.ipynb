{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Klassifikation\n",
    "\n",
    "In diesem Notebook sollen noch verschiedene Klassifikationsbeispiele gezeigt werden - beginnend mit einem sehr einfachen Verfahren (LDA - Linear Discriminant Analysis) und später mit einer SVM (support Vector Machine).\n",
    "\n",
    "Als Datensatz nutzen wir Iris, ein Standarddatensatz für Klassifikationsexperimente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "# TODO\n",
    "# print(iris.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO in Pandas Dataframe verpacken\n",
    "df = pd.DataFrame(...)\n",
    "df_targets = ...\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_targets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns \n",
    "\n",
    "# Für das Plotten kombinieren wir Features und Labels zu einem df\n",
    "combined = pd.concat([df, df_targets], axis=1)\n",
    "\n",
    "# Erzeugen Sie einen Pairplot mit seaborn, dabei sollen alle Kombinationen\n",
    "# von Features geplottet werden (4x4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test/train split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, df_targets['class'], test_size=.2)\n",
    "\n",
    "# Trainieren Sie einen LDA-Klassifier auf den Trainingsdaten\n",
    "lda = LDA()\n",
    "lda.fit(X_train, y_train)\n",
    "\n",
    "# TODO LDA ist gleichzeitig auch eine Methode für \n",
    "# dimensionality reduction\n",
    "\n",
    "# res = lda.transform(df)\n",
    "# plt.scatter(res[:50,0], res[:50,1], color='r')\n",
    "# plt.scatter(res[50:100,0], res[50:100,1], color='g')\n",
    "# plt.scatter(res[100:150,0], res[100:150,1], color='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# TODO wie gut werden die Testdaten klassifiziert? \n",
    "# -> Accuracy score berechnen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "model_svm = SVC(kernel='rbf', gamma=0.7, C=1)\n",
    "\n",
    "# TODO wie gut schneidet eine Support Vector Machine ab?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moons ist ein typischer Beispieldatensatz,\n",
    "# wir nutzenihn, um das Verhalten einer SVM zu\n",
    "# visualisieren\n",
    "\n",
    "from sklearn.datasets import make_moons\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "\n",
    "X, y = make_moons(noise=0.3, random_state=0)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2)\n",
    "\n",
    "figure = plt.figure()\n",
    "\n",
    "# just plot the dataset first\n",
    "cm = plt.cm.RdBu\n",
    "cm_bright = ListedColormap(['#FF0000', '#0000FF'])\n",
    "\n",
    "# Plot the training points\n",
    "plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Trainieren Sie eine SVM auf den Trainingsdaten von Moon,\n",
    "# mit gamma=2, C=1\n",
    "\n",
    "clf =  ...\n",
    "\n",
    "# TODO geben Sie die Accuracy für die Testdaten aus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_min, x_max = X[:, 0].min()-0.5, X[:, 0].max()+0.5\n",
    "y_min, y_max = X[:, 1].min()-0.5, X[:, 1].max()+0.5\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1),\n",
    "                     np.arange(y_min, y_max, 0.1))\n",
    "\n",
    "\n",
    "# TODO um unsere SVM zu visualisieren, können wir die decision_function\n",
    "# an vielen Punkten in der Fläche evaluieren\n",
    "\n",
    "# die Flächenpunkte sind bereits in xx und yy vorbereitet\n",
    "# Allerdings müssen diese noch umgeformt werden\n",
    "Z = clf.decision_function(...)\n",
    "\n",
    "# TODO die Ergebniswerde in Z müssen dann wieder in die \"Flächenform\"\n",
    "# gebracht werden\n",
    "\n",
    "\n",
    "# Plotten\n",
    "# plt.figure()\n",
    "# plt.contourf(xx, yy, Z, cmap=cm, alpha=.8)\n",
    "\n",
    "# plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(tn, fp, fn, tp) = confusion_matrix(y_test, clf.predict(X_test)).ravel()\n",
    "(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formeln für verschiedene Scores:\n",
    "# https://en.wikipedia.org/wiki/Confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "print(accuracy_score(y_test, clf.predict(X_test)))\n",
    "accuracy = ... # TODO einmal von Hand berechnen\n",
    "print(accuracy)\n",
    "\n",
    "# wie viele der als positiv gelabelten Datenpunkte sind tatsächlich positiv?\n",
    "# Wichtig, wenn wir keinen falschen Alarm wollen...\n",
    "print(precision_score(y_test, clf.predict(X_test)))\n",
    "precision = ... # TODO einmal von Hand berechnen\n",
    "print(precision)\n",
    "\n",
    "# wie viele der tatsächlich positiven wurden als solche gelabelt?\n",
    "# Wichtig, wenn wir keinen Fall übersehen wollen...\n",
    "print(recall_score(y_test, clf.predict(X_test)))\n",
    "recall = ... # TODO einmal von Hand berechnen\n",
    "print( recall)\n",
    "\n",
    "# Mittelwert aus Precision und Recall\n",
    "print(f1_score(y_test, clf.predict(X_test)))\n",
    "print(... # TODO einmal von Hand berechnen)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
